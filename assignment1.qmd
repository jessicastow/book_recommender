---
title: "Assignment 1: Recommender Systems"
author: "Jessica Stow (STWJES003@MYUCT.AC.ZA)"
date: "September 2024"
format: 
  html: 
    fig-width: 8
    fig-height: 4
    code-fold: true
---

# Plagiarism declaration

-   I know that plagiarism is wrong.

-   Plagiarism is to use another’s work and pretend that it is one’s own.

-   I have used the required convention for citation and referencing.

-   Each contribution to and quotation in this assignment from the work(s) of other people has been attributed, and has been cited and referenced.

-   This assignment is my own work.

-   I have not allowed, and will not allow, anyone to copy my work with the intention of passing it off as his or her own work.

-   I acknowledge that copying someone else’s assignment or essay, or part of it, is wrong, and declare that this is my own work.

# Objectives

The objectives of this report were as follows:

1\. Build recommender systems that predict the rating a user will give to a book based on each of:

a\) item-based collaborative filtering,

b\) user-based collaborative filtering, and

c\) matrix factorisation.

2\. Assessment and ensemble model:

a\) Assess the accuracy of the matrix factorisation recommender system, using a single train/test sample.

b\) Assess the accuracy of the matrix factorisation recommender system with and without regularisation.

c\) Create a final model that ensembles the predictions from the three approaches, and then assess the accuracy of the ensemble predictions.

# Introduction to Data Mining and Recommender Systems

Recommender systems utilise data mining techniques to offer personalised suggestions by analysing patterns in user preferences and behaviours (Data Mining: Concepts and Techniques, 2012). The collaborative filtering approach specifically focuses on identifying users with similar tastes or preferences, recommending items based on the opinions and actions of those with shared interests. This method may also take into account a user’s social environment to enhance the relevance of the recommendations.

## Cosine Similarity

Cosine similarity is a metric used in both user-based and item-based collaborative filtering to measure how similar two vectors are.

Given two vectors, $\boldsymbol x$ and $\boldsymbol y$, the cosine similarity is defined as:

$$cos(\theta) = \frac{\boldsymbol x \cdot \boldsymbol y}{||\boldsymbol x|| \ ||\boldsymbol y||} = \frac{\sum_{i=1}^{n}x_iy_i}{\sqrt{\sum_{i=1}^{n}x^2_i} \sqrt{\sum_{i=1}^{n}y^2_i}}$$

Cosine similarity ranges from 0 to 1, with higher values indicating greater similarity. As two vectors become more aligned, the angle between them decreases, and the cosine similarity approaches 1, reflecting highly similar user preferences. Conversely, a larger angle results in a cosine similarity closer to 0, indicating that the preferences are very different.

## User-Based Collaborative Filtering

User-Based Collaborative Filtering accounts for a user's interests by identifying similar users and recommending items that those users have shown interest in (Grus, 2015).

To get an idea of how similar two users are we need to use the cosine similarity metric, which quantifies how alike any two users are based on their preference vectors.

## Item-Based Collaborative Filtering

Item-based collaborative filtering (IBCF) takes an alternative approach by computing similarities between items, rather than users. Recommendations are then generated for each user by aggregating items that are similar to the ones the user has shown interest in (Grus, 2015).

Cosine similarity is again used to calculate similarity. If two items are of interest to the same users, their similarity will be closer to 1. If no users show interest in both items, their similarity will be closer to 0. Recommendations are generated by summing the similarities of items related to the user's current interests.

## Collaborative filtering with matrix factorisation

Matrix factorisation offers a different approach to collaborative filtering, rooted in linear algebra, where the goal is to fill in missing values within a matrix. Also known as matrix decomposition, it involves representing a matrix as the product of two smaller matrices. The key concept behind this method is the discovery of **latent factors** — hidden features that capture meaningful patterns in the data.

In recommendation systems, matrix factorisation decomposes the user-item ratings matrix into two smaller matrices in such a way that the known ratings are closely approximated. A key advantage of this approach is that, while the original ratings matrix is incomplete (with missing entries), the decomposed matrices are fully populated. This allows for predicting the missing values in the original matrix, effectively filling in the blanks and making recommendations based on the latent factors derived from the data.

# Data description

The dataset used in this report was obtained from [Kaggle's freely available Book Recommendation Dataset](https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset/). The data was collected by Cai-Nicolas Ziegler in a four-week-long crawl between August and September 2004 from the [Book-Crossing community](https://www.bookcrossing.com/) with kind permission from Ron Hornbaker, CTO of Humankind Systems. It contains 278 858 users (anonymised, but with demographic information) providing over 1 million ratings (explicit/implicit) about 271 379 books.

The dataset consists of three files:

1\. **Users:** which contains the user information:

`User.ID`: the unique, anonymised user identifier.

`Location`: the location of the user (in the format of city, state, country).

`Age`: the age of the user.

2\. **Books:** which contains the book and content based information (which have been obtained from Amazon Web Services):

`ISBN`: the unique identifier for each book.

`Book.Title`: the book title.

`Book.Author`: the book author (in the case of several authors, only the first is provided).

`Year.Of.Publication`: the year of publication.

`Publisher`: the publisher of the book.

`Image-URL-S`, `Image-URL-M`, and `Image-URL-L`: URLs linking to cover images of the books in size small, medium and large, respectively. These URLs point to the Amazon web site.

3\. **Ratings:** which contains the book rating information:

`User.ID`: the unique user id of the user rating the book.

`ISBN`: the ISBN (identifier) of the book rated.

`Book.Rating`: the rating given by the user. These ratings are either explicit (expressed on a scale of 1-10 where higher values indicated higher appreciation), or implicit, expressed by 0.

# Exploratory data analysis

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      error = FALSE,
                      include = FALSE,
                      warning = FALSE)
```

```{r}
# Load libraries
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
library(DT)
library(keras)
library(recosystem)
```

There were no duplicate entries found in any of the datasets. 

The `Books` dataset contains information for 271 360 books, with all of these books being unique based on their ISBN. 

The `Users` dataset contains information for 278 858 users, with all of these users being unique based on their user IDs. 

The `Ratings` dataset contains information for 1 149 780 ratings. For this dataset we found that 105 283 unique users gave ratings (both explicit and implicit), this accounts for approximately 38% of the total user base. Interestingly, these users rated 340 556 books, which exceeds the number of books listed in the `Books` dataset.

```{r}
# read in data
books <- read.csv("data/Books.csv")
ratings <- read.csv("data/Ratings.csv")
users <- read.csv('data/Users.csv')

# BOOKS -----------------------------------------------------------------------
# are all books unique?
nrow(books) # 271 360 books
length(unique(books$ISBN)) # 271 360 books 
nrow(books) == length(unique(books$ISBN)) # YES
sum(duplicated(books)) # no duplicates as expected

# USERS -----------------------------------------------------------------------
# are all users unique?
nrow(users) # 278 858 users
length(unique(users$User.ID)) # 278 858 users
nrow(users) == length(unique(users$User.ID)) # YES
sum(duplicated(users)) # no duplicates as expected



# RATINGS ----------------------------------------------------------------------
# how many ratings
nrow(ratings) # 1 149 780 ratings
sum(duplicated(ratings)) # no duplicates
# how many users gave ratings?
length(unique(ratings$User.ID)) # 105 283

# what percentage of users gave ratings?
round(length(unique(ratings$User.ID))/length(unique(users$User.ID))*100) # ~38%

# how many books were rated?
length(unique(ratings$ISBN)) # 340 556
```

## Univariate analysis

We decided to investigate the following variables:
- user age

We opted to not investigate the user location due to the fact that this was not useful for the purpose of this recommender exercise. 

### User Age 

The user age ranged from 0 to 244 year, with a mean age of 35 years old and median age of 32 years. This is highly problematic since it is impossible for users of age 0 to be reading, and impossible for users to be as old as 244. These outliers are likely to exist due to an error in the data capturing process. When we ignore the strong presence of the high age outliers we can see that the age range is more or less symmetrical and uniform in distribution. 

```{r include=TRUE}
# USERS -----------------------------------------------------------------------
# what is the spread of user ages
min(users$Age, na.rm = TRUE) # minimum age = 0 
mean(users$Age, na.rm = TRUE) # mean age 35 years
median(users$Age, na.rm = TRUE) # 32 
max(users$Age, na.rm = TRUE) # max age 244

# Visualize the range of 'Age' using a boxplot
boxplot(users$Age, 
        main = "Figure 1: Boxplot of User Age", 
        ylab = "Age", 
        col = "lightgreen", 
        horizontal = TRUE)

```

### Book ratings

The book ratings ranged from 0 to 10. Ratings of 0 implied that these ratings were implicit, in other words the user might have read or interacted with the book, but they did not explicitly rate the book. Ratings from 1-10 implied that these ratings were explicit, so the user themself rated these books. We can see from _Figure 2_ below that the majority of the ratings were implicit, which will not be useful in our recommender system later. 

```{r include=TRUE}
# RATINGS -----------------------------------------------------------------------
# what is the spread of the ratings variable
min(ratings$Book.Rating, na.rm = TRUE) # minimum rating = 0 
mean(ratings$Book.Rating, na.rm = TRUE) # mean age 35 years
median(ratings$Book.Rating, na.rm = TRUE) # 32 
max(ratings$Book.Rating, na.rm = TRUE) # max rating = 10

# Visualize the range of 'rating' using a histogram
hist(ratings$Book.Rating, 
     breaks = 11, 
     main = "Figure 2: Distribution of Book rating", 
     xlab = "Book rating",
     col = "lightblue", 
     border = "black",
     xaxt = "n")

# Add custom x-axis with labels from 0 to 10
axis(1, at = 0:10, labels = 0:10)
```

## Bivariate analysis

### Ratings by users

```{r}
# which users rated the most books

# which books got the most ratings

# which books got the highest ratings
```

# Methods

## Data manipulation

### Ratings

We decided to drop the implicit ratings (ratings equal to 0) as these are not useful in the building of our recommender model. We also chose to only keep books with 5 or more ratings to ensure we had enough information to feed our model. This resulted in a ratings data frame with 199 477 rows, meaning 950 303 observations (~83% of our ratings data) was dropped. 

```{r}
ratings <- ratings %>%
  filter(Book.Rating != 0) %>% # Book ratings of zero imply the user did not rate the book, drop rows where rating = 0 
  group_by(ISBN) %>%
  filter(n() > 4) %>% # only keep books with 5 or more ratings
  ungroup()

nrow(ratings) # 199 477 rows, therefore 950 303 rows (83% of the data) dropped
```

## Users 

We decided to only investigate the user preferences of young adults between the ages of 18 and 25 (inclusive). All other ages were dropped from the data frame. 

```{r}
users <- users %>%
  filter(Age >= 18 & Age <= 25) # only keep users between 18 and 25 years old

 
```


### Books

We ensured that all books had a title. We kept the ISBN, book title, author and year of publication information and dropped the publisher and image URLs. 

```{r}
sum(is.na(books$Book.Title)) # all books have a title

books <- books %>%  
  select(c(ISBN, Book.Title, Book.Author, Year.Of.Publication, # keep these variables
           -Publisher, -Image.URL.s, -Image.URL.M, Image.URL.L)) # drop these variables
```

## Joining of books to ratings dataframe

The `Books` data frame was merged with the `Ratings` data frame using a left join on the common variable`ISBN`. This ensured that all the ratings information was retained while adding the corresponding book titles and authors to the data set.

To address the earlier discrepancy where more books were rated than were listed in the `Books` data frame, we checked for any missing book titles. We found that 7 249 ratings lacked corresponding book titles or any other associated information. As a result, we opted to remove these ratings from the data frame.

```{r}
# left join books to ratings df and rename it "ratings_books"
ratings_books <- ratings %>%
  left_join(books, by = "ISBN") %>%
  arrange(User.ID) # order by user ID

sum(is.na(ratings_books$Book.Title)) # 7249 ratings without book info

# Remove rows where Book.Title is NA
ratings_books <- ratings %>% 
  filter(!is.na(Book.Title))

```

## 

```{r}
ratings_books_users <- ratings_books %>%
  inner_join(users, by = "User.ID") %>%
  mutate(User.ID = as.factor(User.ID)) %>%
  mutate(Book.Title = as.factor(Book.Title))
```


## User-Based Collaborative Filtering

## Item-Based Collaborative Filtering

## Collaborative filtering with matrix factorisation

### With regularisation term

### Without regularisation term

### Accuracy assessment of model

## Ensemble model

# Results

## Accuracy assessment of Collaborative filtering with matrix factorisation model

### With regularisation term

### Without regularisation term

# Discussion

# Recommendations

# Conclusion

# References

Grus, J. (2015). Data Science from Scratch: First Principles with Python. 1st ed. O'Reilly Media.

Han, J., Kamber, M. & Pei, J. (2012). Data Mining: Concepts and Techniques, Morgan Kaufmann Publishers, San Francisco, CA, USA.
